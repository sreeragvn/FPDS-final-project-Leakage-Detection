{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "# from sklearn import preprocessing\n",
    "# Make numpy values easier to read.\n",
    "# np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing of data\n",
    "\n",
    "leakage_train_100 = pd.read_csv(\"leakage_dataset_train_100.csv\")\n",
    "leakage_train_1000 = pd.read_csv(\"leakage_dataset_train_1000.csv\")\n",
    "leakage_val_1000 = pd.read_csv(\"leakage_dataset_validation_1000.csv\")\n",
    "\n",
    "# leakage_train_100.head()\n",
    "leakage_val_1000.head()\n",
    "\n",
    "#create two output arrays\n",
    "def format_output(data):\n",
    "    data = data.copy()\n",
    "    y1 = data.pop('y1')\n",
    "    y1 = np.array(y1)\n",
    "    y2 = data.pop('y2')\n",
    "    y2 = np.array(y2)\n",
    "    return y1, y2\n",
    "\n",
    "# X_train = leakage_train_100.iloc[:,2:].to_numpy()\n",
    "# Y_train = leakage_train_100.iloc[:,:2]\n",
    "\n",
    "#splitting of x and y variable\n",
    "X_train = leakage_train_1000.iloc[:,2:].to_numpy()\n",
    "Y_train = leakage_train_1000.iloc[:,:2]\n",
    "\n",
    "num_rows, num_cols = X_train.shape\n",
    "\n",
    "X_validation = leakage_val_1000.iloc[:,2:].to_numpy()\n",
    "Y_validation = leakage_val_1000.iloc[:,:2]\n",
    "\n",
    "# scX = preprocessing.StandardScaler()\n",
    "# X_train = scX.fit_transform(X_train)\n",
    "# X_validation = scX.transform(X_validation)\n",
    "\n",
    "# stY = preprocessing.StandardScaler()\n",
    "# Y_train = stY.fit_transform(Y_train)\n",
    "# Y_validation = stY.transform(Y_validation)\n",
    "\n",
    "# Y_train = pd.DataFrame(Y_train, columns = ['y1','y2'])\n",
    "# Y_validation = pd.DataFrame(Y_validation, columns = ['y1','y2'])\n",
    "\n",
    "y1_train, y2_train = format_output(Y_train)\n",
    "y1_validation, y2_validation = format_output(Y_validation)\n",
    "\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_validation = Y_validation.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42) \n",
    "\n",
    "# NN architechture - keras Functional API\n",
    "# Now we have one input layer, 1 hidden layer and 2 output layer - both connected to hidden layer\n",
    "# Thinking of adding a normalization layer or doing normalization before training\n",
    "# inputs = tf.keras.layers.Normalization(input_shape=[4,], axis=None)\n",
    "inputs = tf.keras.Input(shape=(4,))\n",
    "dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "# dense2_1 = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'y1')\n",
    "# dense2_2 = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'y2')\n",
    "\n",
    "dense2_1 = tf.keras.layers.Dense(1, name = 'y1')\n",
    "dense2_2 = tf.keras.layers.Dense(1, name = 'y2')\n",
    "\n",
    "x=dense1(inputs)\n",
    "\n",
    "outputs1=dense2_1(x)\n",
    "outputs2=dense2_2(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[outputs1, outputs2], name = 'leakge_functional_model')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.mean_absolute_error,\n",
    "              metrics = ['mae']\n",
    ")\n",
    "\n",
    "y = {\n",
    "    \"y1\" : y1_train,\n",
    "    \"y2\" : y2_train\n",
    "}\n",
    "\n",
    "model.fit(X_train, y=y, epochs=5, batch_size=5, verbose=2)\n",
    "\n",
    "predictions = model.predict(X_validation)\n",
    "# print(y)\n",
    "\n",
    "# even for a primilinary result, the loss is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = predictions[0]\n",
    "y2 = predictions[1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.scatter(y1_validation, y1)\n",
    "plt.scatter(y2_validation, y2)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(mean_squared_error(y1_validation, y1, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data Augmentation\n",
    "# Requires cleaning up\n",
    "\n",
    "def rotation_matrix(angle):\n",
    "    theta = np.radians(angle)\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = np.array(((c, -s), (s, c)))\n",
    "    return R\n",
    "\n",
    "def Augmentation_clock(x,y):\n",
    "\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    # print(y)\n",
    "    y_aug = np.transpose(np.matmul(rotation_matrix(90), np.transpose(y)))\n",
    "    # print(y_aug)\n",
    "\n",
    "    temp = x.copy()\n",
    "    x0 = temp[:,0]\n",
    "    x1 = temp[:,1]\n",
    "    x2 = temp[:,2]\n",
    "    x3 = temp[:,3]\n",
    "\n",
    "    # print(x0.shape)\n",
    "\n",
    "    x[:,0] = x3\n",
    "    x[:,1] = x0\n",
    "    x[:,2] = x1\n",
    "    x[:,3] = x2\n",
    " \n",
    "    return x,y_aug\n",
    "\n",
    "\n",
    "def Augmentation_flip(x,y):\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    x = np.flip(x, axis=1)\n",
    "    y[:,1] = -1 * y[:,1]\n",
    "    return x,y\n",
    "\n",
    "def Augmentation_anticlock(x,y):\n",
    "\n",
    "    x = x.copy()\n",
    "    y = y.copy()\n",
    "    # print(y)\n",
    "    y_aug = np.transpose(np.matmul(rotation_matrix(-90), np.transpose(y)))\n",
    "    # print(y_aug)\n",
    "\n",
    "    temp = x.copy()\n",
    "    x0 = temp[:,0]\n",
    "    x1 = temp[:,1]\n",
    "    x2 = temp[:,2]\n",
    "    x3 = temp[:,3]\n",
    "\n",
    "    x[:,0] = x1\n",
    "    x[:,1] = x2\n",
    "    x[:,2] = x3\n",
    "    x[:,3] = x0\n",
    " \n",
    "    return x,y_aug\n",
    "\n",
    "# # test inputs\n",
    "# X_train = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "# # print(X_train)\n",
    "# Y_train = np.array([[15,16], [17,18], [19,20]])\n",
    "# num_rows, num_cols = X_train.shape\n",
    "\n",
    "x_aug1,y_aug1 = Augmentation_clock(X_train, Y_train)\n",
    "x_aug2,y_aug2 = Augmentation_clock(x_aug1,y_aug1)\n",
    "x_aug3,y_aug3 = Augmentation_clock(x_aug2,y_aug2)\n",
    "x_aug4,y_aug4 = Augmentation_flip(x_aug3,y_aug3)\n",
    "x_aug5,y_aug5 = Augmentation_clock(x_aug4,y_aug4)\n",
    "x_aug6,y_aug6 = Augmentation_clock(x_aug5,y_aug5)\n",
    "x_aug7,y_aug7 = Augmentation_clock(x_aug6,y_aug6)\n",
    "    \n",
    "X_train_Aug = np.concatenate((X_train, x_aug1, x_aug2, x_aug3, x_aug4, x_aug5, x_aug6, x_aug7))\n",
    "Y_train_Aug = np.concatenate((Y_train, y_aug1, y_aug2, y_aug3, y_aug4, y_aug5, y_aug6, y_aug7))\n",
    "\n",
    "\n",
    "\n",
    "# def Augmentation(x,y):\n",
    "#     Augmentation1(x,y)\n",
    "#     Augmentation2(x,y)\n",
    "#     Augmentation3(x,y)\n",
    "#     Augmentation4(x,y)\n",
    "#     Augmentation5(x,y)\n",
    "#     Augmentation6(x,y)\n",
    "#     Augmentation7(x,y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failed experiment with Functional API\n",
    "\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Dense, Input\n",
    "\n",
    "\n",
    "# def base_model(inputs):\n",
    "#     x= Dense(128, activation='relu')(inputs)\n",
    "#     x= Dense(128, activation='relu')(x)\n",
    "#     return x\n",
    "\n",
    "# def final_model(inputs):\n",
    "#     x = base_model(inputs)\n",
    "#     y1 = Dense(units='1', name='y1')(x)\n",
    "#     y2 = Dense(units = '1', name = 'y2')(x)\n",
    "#     model = Model(inputs=inputs, outputs = [y1, y2])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# inputs = tf.keras.layers.Input(shape=(4,))\n",
    "# model = final_model(inputs)\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "#               loss=tf.keras.losses.mean_absolute_error,\n",
    "#               metrics = ['mae'])\n",
    "# y = {\n",
    "#     \"y1\" : y1_train,\n",
    "#     \"y2\" : y2_train\n",
    "# }\n",
    "\n",
    "# history = model.fit(X_train, y, epochs=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba7e9f4964f105db5d476a6bf9b47e70d0bf16854eb8b7ea4fd7f47088c3e55f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
