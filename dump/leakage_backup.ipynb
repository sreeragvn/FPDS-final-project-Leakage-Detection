{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# things to do/doubts/discussions\n",
    "# model sometimes give constant loss over epochs and gives poor results on prediction\n",
    "# is the loss value supposed to reduce continously\n",
    "# should we do augmentation of validation data ?\n",
    "# All values are already between -1 to +1. should we do scaling on top of this ?\n",
    "# if we are adding scaling of data, how to ensure that when it is being tested would give out rescaled data\n",
    "\n",
    "\n",
    "# how to save subclassing api\n",
    "# hyperparameter tuning\n",
    "# how to save the best model among all the epochs\n",
    "# should we shuffle repeat, prefetch etc ?\n",
    "# incase of early stopping - what metric is to be monitored - val loss or val mse ?\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "data_size = 1000\n",
    "X_train, Y_train, X_validation, Y_validation, X_test = load_data(data_size)\n",
    "\n",
    "# defining the parameters\n",
    "\n",
    "# loss\n",
    "# Mean Squared Error\n",
    "# Root Mean Squared Error\n",
    "# Mean Absolute Error\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "# steps_per_epoch = sum(train_occurences) / batch_size\n",
    "starter_learning_rate = 1e-1\n",
    "end_learning_rate = 1e-8\n",
    "decay_steps = epochs * 3\n",
    "# loss = tf.keras.losses.MeanAbsoluteError()\n",
    "# loss = tf.keras.losses.MeanSquaredError()\n",
    "loss = 'mean_squared_error'\n",
    "metrics = tf.keras.metrics.MeanSquaredError()\n",
    "scheduler = tf.keras.optimizers.schedules.PolynomialDecay(initial_learning_rate= starter_learning_rate,\n",
    "    decay_steps= decay_steps,\n",
    "    end_learning_rate= end_learning_rate,\n",
    "    power=1)\n",
    "# scheduler = 0.01\n",
    "# optimizer=tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
    "kernel_regularizer=tf.keras.regularizers.L1L2(0.01)\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mean_squared_error',patience=100)]\n",
    "initializer=tf.keras.initializers.HeUniform()\n",
    "\n",
    "verbose=2\n",
    "\n",
    "# generating augmented data\n",
    "X_train_Aug, Y_train_Aug = data_augmentation(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN Model\n",
    "class NNmodel():\n",
    "    def model():\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(Hidden_layer(4, kernel_regularizer=kernel_regularizer, initializer=initializer))\n",
    "        model.add(Output_layer(2, kernel_regularizer=kernel_regularizer, initializer=initializer))\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=scheduler),\n",
    "                    loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "                    metrics = tf.keras.metrics.MeanSquaredError()\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - NN fitting with Normal data\n",
    "model = NNmodel.model()\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size= batch_size, \n",
    "                    verbose=verbose, \n",
    "                    validation_data=(X_validation, Y_validation),\n",
    "                    callbacks=callbacks,\n",
    "                    # shuffle=True\n",
    "                    )  \n",
    "model_eval(model, history, X_validation, Y_validation, X_train, Y_train, batch_size, X_test)\n",
    "model.save('NN_1000_normal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 - NN fitting with Augmented data\n",
    "\n",
    "model = NNmodel.model()\n",
    "history = model.fit(X_train_Aug, Y_train_Aug,\n",
    "                    epochs=epochs, \n",
    "                    batch_size= batch_size, \n",
    "                    verbose=verbose, \n",
    "                    validation_data=(X_validation, Y_validation),\n",
    "                    callbacks=callbacks,\n",
    "                    # shuffle=True\n",
    "                    )  \n",
    "model_eval(model, history, X_validation, Y_validation, X_train_Aug, Y_train_Aug, batch_size, X_test)\n",
    "model.save('NN_1000_Aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivariant NN Model\n",
    "class EqNNmodel():\n",
    "    def model():\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(EqHidden_layer(4, kernel_regularizer=kernel_regularizer, initializer=initializer))\n",
    "        model.add(EqOutput_layer(2, kernel_regularizer=kernel_regularizer, initializer=initializer))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=scheduler),\n",
    "                    loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "                    metrics = tf.keras.metrics.MeanSquaredError()\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 Equivariant NN - on Normal data\n",
    "Eqmodel = EqNNmodel.model()\n",
    "history = Eqmodel.fit(X_train, Y_train,\n",
    "                    epochs=epochs, \n",
    "                    batch_size= batch_size, \n",
    "                    verbose=verbose, \n",
    "                    validation_data=(X_validation, Y_validation),\n",
    "                    callbacks=callbacks,\n",
    "                    # shuffle=True\n",
    "                    )  \n",
    "model_eval(Eqmodel, history, X_validation, Y_validation, X_train, Y_train, batch_size, X_test)\n",
    "Eqmodel.save('ENN_1000_normal.h5',\n",
    "          overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 Equivariant NN - on Augmented data\n",
    "model = EqNNmodel.model()\n",
    "history = model.fit(X_train_Aug, Y_train_Aug,\n",
    "                    epochs=epochs, \n",
    "                    batch_size= batch_size, \n",
    "                    verbose=verbose, \n",
    "                    validation_data=(X_validation, Y_validation),\n",
    "                    callbacks=callbacks,\n",
    "                    # shuffle=True\n",
    "                    )  \n",
    "model_eval(model, history, X_validation, Y_validation, X_train_Aug, Y_train_Aug, batch_size, X_test)\n",
    "model.save('ENN_1000_Aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['NN_1000_normal.h5','NN_1000_Aug.h5','ENN_1000_normal.h5','ENN_1000_Aug.h5', ]\n",
    "# for model in models:\n",
    "import tensorflow_hub as hub\n",
    "from keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'Hidden_layer':hub.KerasLayer}):\n",
    "       load_model = tf.keras.models.load_model('NN_1000_normal.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba7e9f4964f105db5d476a6bf9b47e70d0bf16854eb8b7ea4fd7f47088c3e55f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
